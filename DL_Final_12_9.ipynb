{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " DL_Final 12/9 COPY.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfGj4RPNgA2R",
        "outputId": "f7143abe-39e2-425a-e356-48c159692187"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li4S-KPjHowv"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/ShardDrives/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdRPSGcDgETb",
        "outputId": "92734c08-1d6f-4a9b-c21f-bf5718f3122e"
      },
      "source": [
        "!pip install torchaudio==0.7.0\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/23/6b54106b3de029d3f10cf8debc302491c17630357449c900d6209665b302/torchaudio-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio==0.7.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio==0.7.0) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio==0.7.0) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio==0.7.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchaudio==0.7.0) (3.7.4.3)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr4rL5YlgHJ8",
        "outputId": "4c79a193-7008-4c7c-f710-90954724faf2"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import importlib\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import wave\n",
        "import torchaudio\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.debugger import set_trace\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "gpu_boole = torch.cuda.is_available()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
            "  '\"sox\" backend is being deprecated. '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKC0VM8hVOlY",
        "outputId": "6286ea87-6300-4be2-ccf4-50c9509763e9"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab_Notebooks/DL682/Final/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab_Notebooks/DL682/Final\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZaHU__QCnz0"
      },
      "source": [
        "#Function to write a tensor to a .wav file\n",
        "#Input: tensor with shape [1, L]\n",
        "def tensor2wav(fname, signal, sr):\n",
        "  f = wave.open(fname, 'wb')\n",
        "  f.setnchannels(1)\n",
        "  f.setsampwidth(2)\n",
        "  f.setframerate(sr)\n",
        "  f.writeframes(signal.data.numpy().astype(np.uint16))\n",
        "  f.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gjp6HowEEMUo"
      },
      "source": [
        "#Function to pad sequences so they can be batched\n",
        "\n",
        "#TODO: Create new collate_fn to stack examples on top of each other given they are in the format [N, 1, L]\n",
        "def collate_fn_padd(batch):\n",
        "    '''\n",
        "    Padds batch of variable length\n",
        "    '''\n",
        "    \n",
        "    ## get sequence lengths\n",
        "    sample_lengths = torch.tensor([ t['sample'].shape[0] for t in batch ])\n",
        "    target_lengths = torch.tensor([ t['target'].shape[0] for t in batch ])\n",
        "    ## padd\n",
        "    samples = [ t['sample'] for t in batch ]\n",
        "    targets = [ t['target'] for t in batch ]\n",
        "    samples = torch.nn.utils.rnn.pad_sequence(samples).transpose(0,1)\n",
        "    targets = torch.nn.utils.rnn.pad_sequence(targets).transpose(0,1)\n",
        "    ## compute mask\n",
        "    batch = {'sample': samples.unsqueeze(1), 'target': targets.unsqueeze(1)}\n",
        "    return batch\n",
        "\n",
        "def collate_fn_chunk(batch):\n",
        "    samples, targets = [], []\n",
        "    for t in batch:\n",
        "        samples.append(t['sample'])\n",
        "        targets.append(t['target'])\n",
        "    # concatenate along dimension 0 (chunk/minibatch)\n",
        "    batch = {'sample': torch.cat(samples, dim=0), 'target': torch.cat(targets, dim=0)}\n",
        "    return batch"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dpjVOKCCuYt"
      },
      "source": [
        "#Function to evaluate the model\n",
        "def model_eval(model, dataloader, loss_metric, mode=\"Train\", verbose=True):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  n_batches = 0\n",
        "  total_correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for batch in dataloader:\n",
        "    samples, targets = batch['sample'], batch['target']\n",
        "    if gpu_boole:\n",
        "      samples, targets = samples.cuda(), targets.cuda()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      outputs = model(samples)\n",
        "      loss = loss_metric(outputs, targets)\n",
        "      pred = torch.argmax(outputs, dim = 1)\n",
        "      N = samples.shape[0]\n",
        "      total += N\n",
        "\n",
        "    total_loss += loss.detach()\n",
        "    n_batches += 1\n",
        "\n",
        "  total_loss /= n_batches\n",
        "\n",
        "  if verbose:\n",
        "    print(\"Loss: %1.2f\" %(total_loss.cpu().data.numpy().item()))\n",
        "\n",
        "  return total_loss.cpu().data.numpy().item()\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFEYHxoTrnJa"
      },
      "source": [
        "# data_loader.py\n",
        "\"\"\"\n",
        "Description : Set DataSet module for SimpleUpsampler\n",
        "\"\"\"\n",
        "import torchaudio\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import importlib\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import wave\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "def load_data():\n",
        "  data = torchaudio.datasets.LJSPEECH(root='.', download=True)\n",
        "  return data\n",
        "\n",
        "class testDataset(Dataset):\n",
        "  def __init__(self,data_dir, sample_sr=12000, target_sr=24000 ):\n",
        "    self.files = []\n",
        "    self.data_dir = data_dir\n",
        "    pathname=data_dir\n",
        "    for filename in os.listdir(self.data_dir):\n",
        "      self.files.append(os.path.join(pathname, filename))\n",
        "    self.target_sr = target_sr\n",
        "    self.sample_sr = sample_sr\n",
        "    self.upsample = torchaudio.transforms.Resample(22050, target_sr)\n",
        "    self.downsample = torchaudio.transforms.Resample(target_sr, sample_sr)\n",
        "    self.ratio = target_sr // sample_sr  \n",
        "    self.mu_law = torchaudio.transforms.MuLawEncoding(quantization_channels=256)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    #set_trace()\n",
        "    target, _ = torchaudio.load(self.files[idx])\n",
        "    target_sr = self.target_sr\n",
        "    target = self.upsample(target)\n",
        "    sample = self.transform_audio(target).squeeze(0)\n",
        "    sample_sr = target_sr // self.ratio\n",
        "    target = target.squeeze(0)\n",
        "\n",
        "    # length of a chunk in seconds\n",
        "    chunk_length_sec = 0.5\n",
        "    # length of a chunk in number of samples\n",
        "    chunk_length_sample = int(chunk_length_sec * sample_sr)\n",
        "    chunk_length_target = int(chunk_length_sec * target_sr)\n",
        "    # length of new audio, which must be divisible by the chunk length\n",
        "    # We need to make sure the target sample is a multiple of our SR ratio or else\n",
        "    # We won't be able to recover a sequence exactly the same length\n",
        "    # Here I did not use integer division (or floor), but ceiling to keep all\n",
        "    # samples and fill the rest of the tensor with zeros.\n",
        "    new_length_sample = int(np.ceil(sample.size(0) / chunk_length_sample) * chunk_length_sample)\n",
        "    new_length_target = int(np.ceil(target.size(0) / chunk_length_target) * chunk_length_target)\n",
        "\n",
        "    # create new tensors\n",
        "    _sample = torch.zeros([new_length_sample])\n",
        "    _target = torch.zeros([new_length_target])\n",
        "    _sample[:sample.size(0)] = sample\n",
        "    _target[:target.size(0)] = target\n",
        "\n",
        "    # convert dimensions to [num of chunks, 1, chunk length (fixed)]\n",
        "    sample = _sample.view([-1, 1, chunk_length_sample])\n",
        "    target = _target.view([-1, 1, chunk_length_target])\n",
        "\n",
        "    return {'sample': sample, 'target': target}\n",
        "\n",
        "  def transform_audio(self, signal):\n",
        "    return self.downsample(signal.float())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCdfy7iTpB3d"
      },
      "source": [
        "#Replace with data directory\n",
        "data_dir = '/content/drive/MyDrive/Colab_Notebooks/DL682/Final/LJSpeech-1.1/wavs'\n",
        "data = testDataset(data_dir, sample_sr=12000)\n",
        "#data = testDataset('/content/LJSpeech-1.1/wavs', 'train')\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XHhL_BwDvig",
        "outputId": "2f5b0c85-d4bd-41b8-9afe-da3870eac450"
      },
      "source": [
        "data[0]['sample'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 1, 6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejktapWrm_eH"
      },
      "source": [
        "#Generate train, validation, test splits\r\n",
        "import random\r\n",
        "N = len(data)\r\n",
        "inds = range(len(data))\r\n",
        "random.seed(0)\r\n",
        "train_inds = random.sample(inds, int(0.6 * len(data)))\r\n",
        "remaining = set(inds).difference(set(train_inds))\r\n",
        "validation_inds = random.sample(remaining, int(0.5 * len(remaining)))\r\n",
        "test_inds = remaining.difference(validation_inds)\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmSVw3CLoPqC"
      },
      "source": [
        "train_data = Subset(data, train_inds)\r\n",
        "val_data = Subset(data, validation_inds)\r\n",
        "test_data = Subset(data, list(test_inds))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwcTpGDGoecc"
      },
      "source": [
        "train_loader = DataLoader(train_data, batch_size=2, shuffle=True, collate_fn=collate_fn_chunk)\r\n",
        "val_loader = DataLoader(val_data, batch_size=2, collate_fn=collate_fn_chunk)\r\n",
        "test_loader = DataLoader(test_data, batch_size=2, collate_fn=collate_fn_chunk)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLsnXJYji2K4"
      },
      "source": [
        "class SimpleUpsampler(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleUpsampler, self).__init__()\n",
        "\n",
        "    self.causal_conv = nn.Sequential(\n",
        "        nn.Conv1d(1, 32, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.Conv1d(64, 64, kernel_size=3, dilation=2, padding = 3),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.upsample = nn.ConvTranspose1d(64, 64, kernel_size=8, stride=2, padding=5)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.final_conv = nn.Sequential(\n",
        "        nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(64, 1, kernel_size=5, padding=2),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.causal_conv(x)\n",
        "    out = self.relu(self.upsample(out))\n",
        "    out = self.final_conv(out)\n",
        "    return out"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z40P28_LbQQ-"
      },
      "source": [
        "# # copied version of above for testing \n",
        "\n",
        "class LargeUpsampler(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleUpsampler4, self).__init__()\n",
        "\n",
        "    self.causal_conv = nn.Sequential(\n",
        "        nn.Conv1d(1, 16, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(64, 64, kernel_size=3, dilation=2, padding = 2),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.upsample = nn.ConvTranspose1d(64, 64, kernel_size=8, stride=2, padding=4)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.stage_2 = nn.Sequential(\n",
        "        nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(64, 64, kernel_size=3, dilation=2, padding = 2),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.final_conv = nn.Sequential(\n",
        "        nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(64, 32, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(32, 1, kernel_size=5, padding=2),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "    self.batchnorm = nn.BatchNorm1d(64)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.causal_conv(x)\n",
        "    out = self.relu(self.upsample(out))\n",
        "    out = self.batchnorm(out)\n",
        "    out = self.relu(self.stage_2(out))\n",
        "    out = self.batchnorm(out)\n",
        "    out = self.relu(self.upsample(out))\n",
        "    out = self.final_conv(out)\n",
        "    return out"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0G-HN1H9pPj"
      },
      "source": [
        "# weight initialization\n",
        "\n",
        "def weights_init(model):\n",
        "  for i in model.modules():\n",
        "    if isinstance(i, nn.Conv1d) or isinstance(i, nn.ConvTranspose1d):\n",
        "      nn.init.xavier_uniform_(i.weight.data)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA3wfStJohHV"
      },
      "source": [
        "# calling the network\n",
        "\n",
        "model = SimpleUpsampler()\n",
        "model.apply(weights_init)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "epochs = 10\n",
        "loss_metric = nn.MSELoss()\n",
        "if gpu_boole:\n",
        "  model = model.cuda()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipy5NXzFTDGQ",
        "outputId": "5b1667e1-6c48-4d87-9302-e1752b753206"
      },
      "source": [
        "spec = torchaudio.transforms.Spectrogram().cuda()\r\n",
        "for batch in train_loader:\r\n",
        "  sample = batch['sample'].cuda()\r\n",
        "  out = model(sample)\r\n",
        "  print(out.shape)\r\n",
        "  print(spec(out).shape)\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1, 12000])\n",
            "torch.Size([32, 1, 201, 61])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtE7WjuGS3E9",
        "outputId": "40813f40-f121-4b3d-b499-3a16afa45026"
      },
      "source": [
        "# parameters to calculate in the model \n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f'{total_params:,} total parameters.')\n",
        "# initial design = 101,249 param"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101,889 total parameters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "ikd466_HqEy_",
        "outputId": "977689d8-1a0e-4bd9-8857-4d0a90c3152b"
      },
      "source": [
        "# train_loader = DataLoader(data, batch_size=4, shuffle=True, collate_fn=collate_fn_chunk)\n",
        "# # initial batch_size=2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-cfc175086b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# initial batch_size=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuPbczmbqWyP",
        "outputId": "695e089f-0518-4395-e9c1-fde16b5e7c79"
      },
      "source": [
        "loss_batch = []\n",
        "loss_validation = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  start = timer()\n",
        "\n",
        "  for i, batch in enumerate(train_loader):\n",
        "    samples, targets = batch['sample'], batch['target']\n",
        "    #set_trace()\n",
        "    if gpu_boole:\n",
        "      samples, targets = samples.cuda(), targets.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(samples)\n",
        "    out_freq = spec(outputs)\n",
        "    target_freq = spec(targets)\n",
        "    loss = loss_metric(out_freq, target_freq) + loss_metric(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss = loss.cpu().data.numpy().item()\n",
        "    loss_batch.append(loss)\n",
        "\n",
        "    del loss, outputs\n",
        "    if i % 10 == 0:\n",
        "      print(f'Epoch{epoch}: Time elapsed: {timer() - start:.2f} | Loss: {loss_batch[-1]:.5f} | Memory Allocated: {torch.cuda.memory_allocated()}')\n",
        "  \n",
        "  val_loss = model_eval(model, val_loader, loss_metric, mode=\"Validation\")\n",
        "  loss_validation.append(val_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch0: Time elapsed: 0.34 | Loss: 0.00021 | Memory Allocated: 3129204736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-f2102ac752bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mloss_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "MolsRf9ttvnT",
        "outputId": "7325e248-5d0e-4006-d577-d8872f8fce92"
      },
      "source": [
        "plt.plot(loss_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f49fd785dd8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqtT8b1pOUQb"
      },
      "source": [
        "torch.save(model, 'model.torch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NNi0Xjswr3R"
      },
      "source": [
        "sample = val_data[2]['sample'].reshape(1, -1)\n",
        "target = val_data[2]['target'].reshape(1, -1)\n",
        "tensor2wav('test.wav', sample * 32768, 12000)\n",
        "outputs = model(sample.cuda().unsqueeze(0)).squeeze(0).cpu()\n",
        "tensor2wav('test_out.wav', outputs * 32768, 24000)\n",
        "tensor2wav('test_target.wav', target * 32768, 24000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2jfb64fw4hG",
        "outputId": "98f7e0b2-a1f0-4885-a78a-9e2bd7fbbe78"
      },
      "source": [
        "print(outputs, outputs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0974, -0.6396, -0.8779,  ..., -0.8159,  0.2857,  0.2245]],\n",
            "       grad_fn=<CopyBackwards>) torch.Size([1, 156000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4-riGdFx7pr",
        "outputId": "a3978b0b-035e-4540-e298-c305ec7453c7"
      },
      "source": [
        "print(sample, sample.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0051,  0.0060, -0.0032,  ...,  0.0000,  0.0000,  0.0000]]) torch.Size([1, 66000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z5NFI62zVHo",
        "outputId": "d289d32d-d7d6-4d49-a7fd-a10b060b01c8"
      },
      "source": [
        "print(val_data[0]['target'].reshape(1, -1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[9.1344e-05, 1.2265e-04, 1.2041e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5VIDuDqYrwm"
      },
      "source": [
        "#Lite model vs large model, replace names with whatever model you want to test\r\n",
        "lite = torch.load('lite.torch').cuda()\r\n",
        "large = torch.load('large.torch').cuda()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-PY7ZgDzY_Q"
      },
      "source": [
        "eval_inds = random.sample(range(len(test_inds)), 300)\r\n",
        "eval_data = Subset(test_data, eval_inds)\r\n",
        "eval_loader = DataLoader(eval_data, batch_size=10, collate_fn=collate_fn_chunk)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIpTsrFsahvZ"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtojYsChYhBs",
        "outputId": "29a45a3d-ccf0-478e-a633-7de7d0ce89a1"
      },
      "source": [
        "loss_metric = nn.MSELoss()\r\n",
        "\r\n",
        "base_loss = []\r\n",
        "lite_loss = []\r\n",
        "large_loss = []\r\n",
        "N = 0\r\n",
        "\r\n",
        "base = torchaudio.transforms.Resample(12000, 24000)\r\n",
        "\r\n",
        "for batch in tqdm(eval_loader):\r\n",
        "  samples, targets = batch['sample'], batch['target']\r\n",
        "  with torch.no_grad():\r\n",
        "\r\n",
        "    base_pred = base(samples)\r\n",
        "    base_loss.append(loss_metric(base_pred, targets))\r\n",
        "    samples, targets = samples.cuda(), targets.cuda()\r\n",
        "\r\n",
        "    lite_pred = lite(samples)\r\n",
        "    N += samples.shape[0]\r\n",
        "    #large_pred = large(samples)\r\n",
        "    lite_loss.append(loss_metric(lite_pred, targets).cpu())\r\n",
        "    #large_loss.append(loss_metric(large_pred, targets).cpu())"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 1/30 [00:01<00:45,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  7%|▋         | 2/30 [00:03<00:43,  1.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|█         | 3/30 [00:05<00:44,  1.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 13%|█▎        | 4/30 [00:06<00:43,  1.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 5/30 [00:08<00:42,  1.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 20%|██        | 6/30 [00:10<00:40,  1.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 23%|██▎       | 7/30 [00:11<00:37,  1.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 27%|██▋       | 8/30 [00:13<00:36,  1.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 30%|███       | 9/30 [00:14<00:33,  1.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 10/30 [00:16<00:32,  1.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 37%|███▋      | 11/30 [00:18<00:33,  1.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 40%|████      | 12/30 [00:20<00:31,  1.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 43%|████▎     | 13/30 [00:21<00:28,  1.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 47%|████▋     | 14/30 [00:23<00:28,  1.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 15/30 [00:25<00:26,  1.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 53%|█████▎    | 16/30 [00:27<00:24,  1.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 57%|█████▋    | 17/30 [00:28<00:22,  1.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 60%|██████    | 18/30 [00:30<00:20,  1.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 63%|██████▎   | 19/30 [00:32<00:18,  1.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 20/30 [00:34<00:17,  1.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 70%|███████   | 21/30 [00:35<00:15,  1.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 73%|███████▎  | 22/30 [00:37<00:13,  1.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 77%|███████▋  | 23/30 [00:38<00:11,  1.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 80%|████████  | 24/30 [00:40<00:09,  1.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 25/30 [00:42<00:08,  1.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 87%|████████▋ | 26/30 [00:43<00:06,  1.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 90%|█████████ | 27/30 [00:45<00:05,  1.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 28/30 [00:47<00:03,  1.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 29/30 [00:49<00:01,  1.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 30/30 [00:51<00:00,  1.70s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pri7CXvkZ4v8",
        "outputId": "0bc8f4e5-a9be-4b22-e226-0f0ecaba4252"
      },
      "source": [
        "np.array(base_loss).mean() "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004559212"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFO6irYocIQL",
        "outputId": "f0b7b220-33fe-415f-aa16-80fc469aaf63"
      },
      "source": [
        "np.array(lite_loss).mean()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00043919904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHNnAcgJfigW",
        "outputId": "86920178-08c5-4b70-e79c-291602f90462"
      },
      "source": [
        "np.array(base_loss).std() / np.sqrt(N)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5543495976941718e-06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mx_Bm6Hhisd",
        "outputId": "c2e9d0cd-6b49-4cd3-cd4b-f2d89d4b9970"
      },
      "source": [
        "np.array(lite_loss).std() / np.sqrt(N)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5292641641566676e-06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9byQPYu7hlp_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}